{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fc7e306",
   "metadata": {},
   "source": [
    "# Erster Korrekturschritt: Verzeichnung\n",
    "\n",
    "Im ersten Korrekturschritt werden zuerst die intrinsischen Kameraparameter sowie die Verzeichnungsparameter bestimmt. Dafür wird mit dem \"Pinhole-Modell\" ein Zusammenhang zwischen Weltkoordinaten und Bildkoordinaten hergestellt. \n",
    "\n",
    "\n",
    "![Pinhole-Kamera-Modell](media/pinhole.png)\n",
    "<center>Pinhole-Modell (https://docs.opencv.org/4.5.5/d9/d0c/group__calib3d.html)</center>\n",
    "\n",
    "\n",
    "Für die Umsetzung werden Schachbrettbilder genutzt, die mit derselben Kamera wie die zu korrigierenden Bilder aufgenommen wurden. Die Schnittpunkte des Schachbrettmusters (Stellen, an denen sich jeweils vier Felder treffen) werden als Weltkoordinaten definiert und im Anschluss auf SubPixel-Niveau im Bild detektiert (Bildkoordinaten).\n",
    "\n",
    "Die berechneten intrinsischen Kameraparameter und Verzeichungsparameter werden anschließend auf sämtliche Nadir-Bilder angewendet, wodurch die Verzeichnung korrigiert wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a087e6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, glob, os\n",
    "import numpy as np\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "chess_path = r\"./chess/\" # Pfad der Schachbrettbilder\n",
    "input_path = r\"./input/\" # Pfad der Nadir-Rohdaten\n",
    "output1_path = r\"./output1/\" # Pfad der primär korrigierten Nadir-Bilder\n",
    "\n",
    "horizontal_corner_points = int(input(\"\\nAnzahl horizontaler Schachtfelder: \"))-1\n",
    "vertical_corner_points = int(input(\"Anzahl vertikaler Schachfelder: \"))-1\n",
    "square_size = float(input(\"Seitenlänge eines Feldes [mm]: \"))\n",
    "\n",
    "# Arrays für Weltkoordinaten (objpoints) und Bildkoordinaten (imgpoints)\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ea76af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition der Weltkoordinaten (0,0,0), (1,0,0), (2,0,0)...\n",
    "objp = np.zeros((vertical_corner_points * horizontal_corner_points, 3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:vertical_corner_points, 0:horizontal_corner_points].T.reshape(-1,2)\n",
    "objp *= square_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85e58b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chess_images = glob.glob(chess_path + \"*.jpg\")\n",
    "f = IntProgress(min=0, max=len(chess_images), description='Analyse:',bar_style='warning')\n",
    "display(f)\n",
    "\n",
    "print(\"\\nAnalyse der Schachbrettbilder:\")\n",
    "\n",
    "# Einlesen eines jeden JPGs im Schachbrettverzeichnis\n",
    "for chess_img in chess_images:\n",
    "    \n",
    "    # Umwandlung in Graustufe\n",
    "    gray_img = cv2.imread(chess_img, 0)\n",
    "    \n",
    "    #print(chess_img)\n",
    "                    \n",
    "    # Detektion der Schnittpunkte im Schachbrettmuster\n",
    "    ret, corners = cv2.findChessboardCorners(gray_img, (vertical_corner_points, horizontal_corner_points), None)\n",
    "\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "\n",
    "        #criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_COUNT, 30, 0.1)\n",
    "        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "        \n",
    "        # Bestimmung der Schnittpunkte im SubPixel-Bereich\n",
    "        #corners2 = cv2.cornerSubPix(gray_img,corners,(11,11),(-1,-1),criteria)\n",
    "        corners2 = cv2.cornerSubPix(gray_img,corners,(5,5),(-1,-1),criteria)\n",
    "        imgpoints.append(corners2)\n",
    "        print(\"%s...\" % chess_img,\"ok\")\n",
    "\n",
    "    else:\n",
    "        print(\"%s ...\" % chess_img,\"kein Schachbrettmuster gefunden\")\n",
    "    \n",
    "    f.value += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa4deed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnung der intrinsischen und extrinsischen Kameraparameter anhand der Welt- und Bildkoordinaten\n",
    "if len(imgpoints) != 0 and len(objpoints) != 0:\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray_img.shape[::-1], None, None)\n",
    "    print(\"\\nVerzeichnungsparameter bestimmt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fb6894",
   "metadata": {},
   "outputs": [],
   "source": [
    "nadir_images = glob.glob(input_path + \"*.jpg\")\n",
    "f = IntProgress(min=0, max=len(nadir_images), description='Korrektur:',bar_style='info')\n",
    "display(f)\n",
    "\n",
    "# Einlesen eines jeden Bildes im Input-Verzeichnis\n",
    "for image in nadir_images:\n",
    "    \n",
    "    print(\"Korrigiere ... \", image)\n",
    "    img = cv2.imread(image)\n",
    "    h, w = img.shape[:2]\n",
    "     \n",
    "    # Anwenden der berechneten Verzeichnungsparameter auf das eingelesene Bild\n",
    "    newcameramtx, roi=cv2.getOptimalNewCameraMatrix(mtx,dist,(w,h),0,(w,h))\n",
    "    \n",
    "    # Korrektur der Verzeichnung\n",
    "    new_img = cv2.undistort(img, mtx, dist, None, newcameramtx)\n",
    "\n",
    "    # Bild zuschneiden\n",
    "    #x,y,w2,h2 = roi\n",
    "    #newimg = newimg[y:y+h2, x:x+w2]\n",
    "                                    \n",
    "    new_img_name = image[8:]\n",
    "    cv2.imwrite(output1_path + new_img_name, new_img)\n",
    "    f.value += 1\n",
    "    \n",
    "print(\"\\nAlle Bilder korrigiert und im 'output1'-Ordner gespeichert.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1413791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnung des durchschnittlichen Fehlers (je näher 0, desto besser)\n",
    "mean_error = 0\n",
    "for i in range(len(objpoints)):\n",
    "    imgpoints2, _ = cv2.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)\n",
    "    error = cv2.norm(imgpoints[i],imgpoints2, cv2.NORM_L2)/len(imgpoints2)\n",
    "    mean_error += error\n",
    "print(mean_error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
